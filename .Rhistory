x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
boosting_tune_res <- tune_grid(
boosting_tune_wf,
resamples = cv_folds,
grid = boosting_grid,
metrics = class_metrics
)
boosting_tune_metrics <-
boosting_tune_res |>
collect_metrics()
boosting_tune_metrics
boosting_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(
x = trees, y = 1 - mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Misclassification rate") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate, labeller = label_both) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .98),
legend.justification = c(1, 1),
legend.background = element_rect(colour = "black")
)
boosting_tune_metrics |>
filter(.metric == "sensitivity") |>
ggplot(aes(
x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Sensitivity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .98),
legend.justification = c(1, 1),
legend.background = element_rect(colour = "black")
)
boosting_tune_metrics |>
filter(.metric == "specificity") |>
ggplot(aes(
x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
) |>
filter(.metric == "specificity") |>
ggplot(aes(
x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
boosting_tune_metrics |>
filter(.metric == "specificity") |>
ggplot(aes(
x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
) |>
filter(.metric == "specificity") |>
ggplot(aes(
x = trees, y = mean,
colour = factor(tree_depth)
)) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
boosting_tune_metrics |>
filter(.metric == "specificity") |>
ggplot(aes(x = trees, y = mean, colour = factor(tree_depth))) +
geom_path() +
labs(y = "Specificity") +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~learn_rate) +
labs(colour = "tree_depth") +
theme_bw() +
theme(
legend.position = c(.98, .02),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate) |>
update_role(AppDate, OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
boosting_tune_metrics |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(x = trees, y = mean, colour = .metric)) +
geom_path() +
facet_grid(learn_rate ~ tree_depth, labeller = label_both) +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
theme_bw() +
labs(y = NULL) +
theme(
legend.position = c(.98, .2),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
set.seed(82001)
boosting_tune_metrics |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(x = trees, y = mean, colour = .metric)) +
geom_path() +
facet_grid(learn_rate ~ tree_depth, labeller = label_both) +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
theme_bw() +
labs(y = NULL) +
theme(
legend.position = c(.98, .2),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
boosting_best <-
boosting_tune_metrics |>
filter(tree_depth == 3, learn_rate == 0.1, trees == 3500) |>
distinct(trees, tree_depth, learn_rate)
boosting_final_wf <-
finalize_workflow(boosting_tune_wf, boosting_best)
boosting_final_wf
boosting_final_fit <-
boosting_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
boosting_test_results <-
boosting_final_fit |>
collect_metrics()
boosting_test_results
library(tidymodels)
library(tidyverse)
library(skimr)
set.seed(221102)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate) |>
update_role(AppDate, OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 10)), levels = 10)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
# Test set
set.seed(666420)
rf_final_fit <-
rf_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
rf_final_fit |>
collect_metrics()
rf_final_fit |>
collect_predictions() |>
conf_mat(truth = Status, estimate = .pred_class)
rf_recipe_downsample
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 14)), levels = 14)
View(offers)
library(tidymodels)
library(tidyverse)
library(skimr)
set.seed(221102)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(OfferDate,ResponseDate) |>
update_role(OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 15)), levels = 15)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
5 roc_auc     binary        0.865  Preprocessor1_Model1
show_notes(.Last.tune.result)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate) |>
update_role(AppDate, OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate, ResponseDate) |>
update_role(AppDate, OfferDate, ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 15)), levels = 15)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 14)), levels = 14)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
# Test set
set.seed(666420)
rf_final_fit <-
rf_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
rf_final_fit |>
collect_metrics()
rf_final_fit |>
collect_predictions() |>
conf_mat(truth = Status, estimate = .pred_class)
rf_final_fit |>
collect_metrics()
