scale_colour_manual(values = c("#D55E00", "#0072B2")) +
theme_bw() +
labs(y = NULL) +
theme(
legend.position = c(.98, .2),
legend.justification = c(1, 0),
legend.background = element_rect(colour = "black")
)
boosting_best <-
boosting_tune_metrics |>
filter(tree_depth == 3, learn_rate == 0.1, trees == 3500) |>
distinct(trees, tree_depth, learn_rate)
boosting_final_wf <-
finalize_workflow(boosting_tune_wf, boosting_best)
boosting_final_wf
boosting_final_fit <-
boosting_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
boosting_test_results <-
boosting_final_fit |>
collect_metrics()
boosting_test_results
library(tidymodels)
library(tidyverse)
library(skimr)
set.seed(221102)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate) |>
update_role(AppDate, OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 10)), levels = 10)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
# Test set
set.seed(666420)
rf_final_fit <-
rf_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
rf_final_fit |>
collect_metrics()
rf_final_fit |>
collect_predictions() |>
conf_mat(truth = Status, estimate = .pred_class)
rf_recipe_downsample
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 14)), levels = 14)
View(offers)
library(tidymodels)
library(tidyverse)
library(skimr)
set.seed(221102)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(OfferDate,ResponseDate) |>
update_role(OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 15)), levels = 15)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
5 roc_auc     binary        0.865  Preprocessor1_Model1
show_notes(.Last.tune.result)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate) |>
update_role(AppDate, OfferDate,ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate, ResponseDate) |>
update_role(AppDate, OfferDate, ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 15)), levels = 15)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 14)), levels = 14)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
# Test set
set.seed(666420)
rf_final_fit <-
rf_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
rf_final_fit |>
collect_metrics()
rf_final_fit |>
collect_predictions() |>
conf_mat(truth = Status, estimate = .pred_class)
rf_final_fit |>
collect_metrics()
library(tidymodels)
library(tidyverse)
load("data/offers_censored.RData")
# We need to set a seed
set.seed(666420)
final_training_prediction_split <-
offers |>
make_appyear_split(test_year = 2023)
source("./helpful_functions.R")
final_training_prediction_split <-
offers |>
make_appyear_split(test_year = 2023)
final_training <- training(final_training_prediction_split)
analysis_assessment_split <-
offers |>
censor_post_prediction_responses(years = 2022)|>
drop_post_prediction_offers()|>
filter(AppYear <= 2022) |>
make_appyear_split(test_year = 2022)
analysis_train <- training(analysis_assessment_split)
assessment_test <- testing(analysis_assessment_split)
set.seed(221102)
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate, ResponseDate) |>
update_role(AppDate, OfferDate, ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 3000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 14)), levels = 14)
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 20)), levels = 14)
rf_tune_grid
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 20)), levels = 15)
rf_tune_grid
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 25)), levels = 15)
rf_tune_grid
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 25)), levels = 12)
rf_tune_grid
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 25)), levels = 13)
rf_recipe_downsample
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 25)), levels = 14)
rf_tune_grid
# CV folds
cv_folds <-
analysis_train |>
vfold_cv(v = 10, strata = Status)
skim(analysis_train)
# Defining the random forest model
rf_recipe_downsample <-
recipe(Status ~., data = analysis_train) |>
step_rm(AppDate, OfferDate, ResponseDate) |>
update_role(AppDate, OfferDate, ResponseDate, new_role = "metadata") |>
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
rf_recipe_downsample
# Define the random forest model
rf_model_tune <-
rand_forest(mtry = tune(), trees = 1000) |>
set_mode("classification") |>
set_engine("ranger", importance = "permutation")
rf_tune_wf <-
workflow() |>
add_recipe(rf_recipe_downsample) |>
add_model(rf_model_tune)
class_metrics <- metric_set(
accuracy, kap, sensitivity,
specificity, roc_auc
)
# Tuning the model
rf_tune_grid <- grid_regular(mtry(range = c(1, 25)), levels = 14)
rf_tune_grid
num_cores <- parallel::detectCores()
num_cores
doParallel::registerDoParallel(cores = num_cores - 1L)
set.seed(231164)
rf_tune_res <- tune_grid(
rf_tune_wf,
resamples = cv_folds,
grid = rf_tune_grid,
metrics = class_metrics
)
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("sensitivity", "specificity")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err,
colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
rf_tune_res |>
collect_metrics() |>
filter(.metric %in% c("roc_auc", "accuracy", "kap")) |>
ggplot(aes(
x = mtry, y = mean, ymin = mean - std_err,
ymax = mean + std_err, colour = .metric
)) +
geom_errorbar() +
geom_line() +
geom_point() +
scale_colour_manual(values = c("#D55E00", "#0072B2", "#009E73")) +
facet_wrap(~.metric, ncol = 1, scales = "free_y") +
guides(colour = "none") +
theme_bw()
best_rf <- select_best(rf_tune_res, "sensitivity")
rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
rf_final_wf
# Test set
set.seed(666420)
rf_final_fit <-
rf_final_wf |>
last_fit(analysis_assessment_split, metrics = class_metrics)
rf_final_fit |>
collect_metrics()
