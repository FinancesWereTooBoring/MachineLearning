cv_folds <- vfold_cv(analysis_train, v = 7) #I have no clue if it's needed
grid_lasso <- grid_regular(penalty(),
levels = 20)
lasso_tune <-
lasso_wf %>%
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(rmse, rsq_trad, mae))
beepr::beep()
analysis_train
linear_reg_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate, Program)|>
step_dummy(all_nominal_predictors()) |>
#step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(linear_reg_recipe) |>
add_model(lasso_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 7) #I have no clue if it's needed
grid_lasso <- grid_regular(penalty(),
levels = 20)
lasso_tune <-
lasso_wf %>%
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(rmse, rsq_trad, mae))
beepr::beep()
library(tidymodels)
library(tidyverse)
library(beepr)
source("./data_processing.R")
lasso_reg <- linear_reg(penalty = tune(), mixture = 1) %>%
set_engine("glmnet")
linear_reg_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(linear_reg_recipe) |>
add_model(lasso_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 7) #I have no clue if it's needed
grid_lasso <- grid_regular(penalty(c(1, 4), trans = log10_trans()),
levels = 40)
lasso_tune <-
lasso_wf %>%
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(rmse, rsq_trad, mae))
beepr::beep()
show_notes(.Last.tune.result)
analysis_train
library(tidymodels)
library(tidyverse)
library(beepr)
source("./data_processing.R")
lasso_logistic_reg <-
logistic_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(lasso_recipe) |>
add_model(lasso_logistic_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 10)
grid_lasso <- grid_regular(penalty(c(1, 4), trans = log10_trans()),
levels = 40)
lasso_tune <-
lasso_wf %>%
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(rmse, rsq_trad, mae))
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
beepr::beep()
show_notes(.Last.tune.result)
library(tidymodels)
library(tidyverse)
library(beepr)
source("./data_processing.R")
lasso_logistic_reg <-
logistic_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
# step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(lasso_recipe) |>
add_model(lasso_logistic_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 10) #I have no clue if it's needed
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
lasso_tune_metrics <-
lasso_tune %>%
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "rmse") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5) +
scale_x_log10() +
labs(y = "RMSE", x = expression(lambda)) +
theme_bw()
lasso_tune_metrics
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -2),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4, -1.3),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4, -1.1),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
lasso_1se_model <-
lasso_tune |>
select_by_one_std_err(metric = "accuracy", desc(penalty))
lasso_1se_model
lasso_wf_tuned <-
lasso_wf |>
finalize_workflow(lasso_1se_model)
lasso_wf_tuned
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
step_dummy(all_outcomes()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(lasso_recipe) |>
add_model(lasso_logistic_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 10) #I have no clue if it's needed
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
lasso_1se_model
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
# I still include interaction terms
step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(lasso_recipe) |>
add_model(lasso_logistic_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 10) #I have no clue if it's needed
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#Well, at least it works now. But we`ll need to discuss which metrics to take.
beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
lasso_tune |>
select_by_one_std_err(metric = "accuracy", desc(penalty))
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#Well, at least it works now. But we`ll need to discuss which metrics to take.
beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
lasso_tune |>
select_by_one_std_err(metric = "accuracy", desc(penalty))
library(tidymodels)
library(tidyverse)
library(beepr)
source("./data_processing.R")
lasso_logistic_reg <-
logistic_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
lasso_recipe <-
recipe(Status ~ ., data = analysis_train) |>
step_rm(AppDate, OfferDate,ResponseDate)|>
step_dummy(all_nominal_predictors()) |>
# I still include interaction terms
#step_interact(~ all_predictors():all_predictors()) |>
# remove any resulting variables that have only one value
# and thus zero variance ("zv")
step_zv(all_predictors()) |>
# normalize the predictors to have mean 0 and SD 1
step_normalize(all_predictors())
lasso_wf <-
workflow() |>
add_recipe(lasso_recipe) |>
add_model(lasso_logistic_reg)
set.seed(1810)
cv_folds <- vfold_cv(analysis_train, v = 10) #I have no clue if it's needed
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#Well, at least it works now. But we`ll need to discuss which metrics to take.
beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
# Assume that the correct model is already chosen
lasso_1se_model <-
lasso_tune |>
select_by_one_std_err(metric = "accuracy", desc(penalty))
acc <- 0.956
lasso_wf_tuned <-
lasso_wf |>
finalize_workflow(lasso_1se_model)
grid_lasso <-
grid_regular(penalty(range = c(-4.5, -1.5),
trans = log10_trans()),
levels = 100)
lasso_tune <-
lasso_wf |>
tune_grid(resamples = cv_folds,
grid = grid_lasso,
metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
#Well, at least it works now. But we`ll need to discuss which metrics to take.
beepr::beep()
lasso_tune_metrics <-
lasso_tune |>
collect_metrics()
lasso_tune_metrics |>
filter(.metric == "accuracy") |>
ggplot(aes(x = penalty, y = mean,
ymin = mean - std_err, ymax = mean + std_err)) +
geom_pointrange(alpha = 0.5, size = .125) +
scale_x_log10() +
labs(y = "Accuracy", x = expression(lambda)) +
theme_bw()
# Assume that the correct model is already chosen
lasso_1se_model <-
lasso_tune |>
select_by_one_std_err(metric = "accuracy", desc(penalty))
acc <- 0.956
lasso_wf_tuned <-
lasso_wf |>
finalize_workflow(lasso_1se_model)
lasso_last_fit <-
lasso_wf_tuned |>
last_fit(analysis_assessment_split, metrics = metric_set(accuracy, f_meas, kap, bal_accuracy))
lasso_last_fit
lasso_test_metrics <-
lasso_test_metrics |>
select(.metric, .estimate) |>
mutate(model = "lasso")
lasso_test_metrics <-
lasso_last_fit |>
collect_metrics()
lasso_test_metrics <-
lasso_test_metrics |>
select(.metric, .estimate) |>
mutate(model = "lasso")
lasso_test_metrics
gc()
